---
title: "Questions around Cabral et al. 2020"
author: 
  - Daniel Ovando
  - Owen Liu
  - Renato Molina
  - Cody Szuwalski
date: "`r Sys.Date()`"
output: bookdown::pdf_document2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
```

We worry that the prescnedent set here allows for easy arguments along the lines of "yes, only 5% for most of the gaines, but 90%+ for no losses, so what are the chances that this little area we're debating about would be bad for food secutiry"

```{r, echo = FALSE, include=FALSE}

#copied and then modified to allow reproducibility from FoodGlobalAnalysis_EffortRedistribute_clean.R supplied by Ren through
# https://ucsb.box.com/s/mj6gnsh111c0nrdw1yt4nutvkts76zi4

library(foreach)
library(doParallel)
library(raster)
library(rgdal)
library(maptools)
library(dplyr)
library(pryr)
library(ggplot2)
library(cowplot)
library(reshape)
library(data.table)
library(here)
library(scales)
library(tidyverse)
library(countrycode)
library(patchwork)
# library(marlin)
library(devtools)
#install_github("ropensci/ramlegacy")
library(ramlegacy)
library(sf)

rename <- dplyr::rename

run_cabral_et_al <- FALSE

run_case_study <- FALSE

get_fao_data <- TRUE

run_ram_exmaple <- FALSE

results_name <- "v0.5"

results_path <- here("results", results_name)

if (!dir.exists(results_path)){
  dir.create(results_path, recursive = TRUE)
}

if (!dir.exists("data")){

     download.file(
      "https://www.dropbox.com/s/vrewj7ryqbbs0a4/food-provision-data.zip?dl=1",
      destfile = here("tmp.zip"),
      mode = "wb"
    )

    unzip(here("tmp.zip")) # unzip = 'unzip' needed for windows
    
    # file.rename("food-provision-data","data")
    
    file.remove("tmp.zip")
    
    if (dir.exists("__MACOSX")){
      unlink("__MACOSX", recursive = TRUE)
    }
  
}

if (get_fao_data | !dir.exists(here("data", "fao"))) {
  if (!dir.exists(here("data", "fao"))) {
    dir.create(here("data", "fao"))

    download.file(
      "http://www.fao.org/fishery/static/Data/Capture_2020.1.0.zip",
      destfile = here("data", "fao.zip"),
      mode = "wb"
    )

    unzip(here("data", "fao.zip"), exdir = here("data", "fao"))

    file.remove(here("data", "fao.zip"))

    download.file(
      "http://www.fao.org/fishery/static/ASFIS/ASFIS_sp.zip",
      destfile = here("data", "asfis.zip"),
      mode = "wb"
    )

    unzip(here("data", "asfis.zip"), exdir = here("data", "fao"))

    file.remove(here("data", "asfis.zip"))


  }


  asfis <-
    read_delim(here("data", "fao", "ASFIS_sp_2020.txt"), delim = ",") %>%
    janitor::clean_names() %>%
    rename(isscaap_code = isscaap) %>%
    select(isscaap_code, scientific_name, taxocode) %>%
    unique()

  # major issue with NEIs here. There is no database that has both isscaap group and isscaap code, so you need
  # to do a complicated merge based on scientific name.

  fao_capture <-
    read_csv(here("data", "fao", "TS_FI_CAPTURE.csv")) %>%
    janitor::clean_names()

  sp_groups <-
    read_csv(here("data", "fao", "CL_FI_SPECIES_GROUPS.csv")) %>%
    janitor::clean_names() %>%
    select(x3alpha_code:identifier, contains("_en"), author:cpc_group) %>%
    rename(species_name_en = name_en) %>%
    left_join(asfis, by = c("taxonomic_code" = "taxocode"))

  # sp_groups %>%
  #   group_by(x3alpha_code) %>%
  #   summarise(ni = n_distinct(isscaap_group)) %>%
  #   arrange(desc(ni))

  country_groups <-
    read_csv(here("data", "fao", "CL_FI_COUNTRY_GROUPS.csv")) %>%
    janitor::clean_names() %>%
    mutate(un_code = as.numeric(un_code)) %>%
    select(un_code:iso3_code, contains("_en")) %>%
    rename(country_name_en = name_en,
           country_official_name_en = official_name_en)

  fao_areas <-
    read_csv(here("data", "fao", "CL_FI_WATERAREA_GROUPS.csv")) %>%
    janitor::clean_names() %>%
    mutate(fishing_area = as.numeric(code)) %>%
    select(fishing_area, contains("_en"), contains("group"))

  fao_capture <- fao_capture %>%
    left_join(sp_groups, by = c("species" = "x3alpha_code"))

  fao_capture <- fao_capture %>%
    left_join(country_groups, by = c("country" = "un_code")) %>%
    left_join(fao_areas, by = "fishing_area")

  fao_capture$fao_country_name <-
    countrycode::countrycode(fao_capture$country_name_en, "country.name", "un.name.en")

  fao_capture <- fao_capture %>%
    mutate(country = case_when(
      is.na(fao_country_name) ~ country_name_en,
      TRUE ~ fao_country_name
    )) %>%
    mutate(continent = countrycode::countrycode(country, "country.name", "continent"))

  fao_capture <- fao_capture %>%
    rename(
      isscaap_number = isscaap_code,
      common_name = species_name_en,
      capture = quantity,
      capture_units = unit,
      fao_area_code = fishing_area,
      fao_area = name_en
    ) %>%
    mutate(fao_stock = paste(common_name, country, fao_area, sep = '_'))

  fao_capture <- fao_capture %>%
    group_by(fao_stock) %>%
    nest() %>%
    ungroup() %>%
    mutate(id = 1:nrow(.)) %>%
    unnest(cols = data)

  fao_capture <- fao_capture %>%
    select(id, fao_stock, everything())

  fao <- fao_capture %>%
    filter(capture_units == "t",
           isscaap_number < 67)

  assign("fao", fao, envir = .GlobalEnv)


  fao_stock_lookup <- fao %>%
    select(scientific_name,
           common_name,
           country,
           fao_area,
           fao_area_code) %>%
    unique()

  assign("fao_stock_lookup", fao_stock_lookup, envir = .GlobalEnv)


  fao_species <- fao %>%
    select(scientific_name, common_name, isscaap_group, isscaap_number) %>%
    unique()

  assign("fao_species", fao_species, envir = .GlobalEnv)

  fao_genus <-
    str_split(fao_species$scientific_name, ' ', simplify = TRUE)[, 1]

  fao_genus <-  fao_species %>%
    mutate(genus = fao_genus) %>%
    group_by(genus, isscaap_group) %>%
    count() %>%
    group_by(genus) %>%
    filter(n == max(n)) %>%
    select(-n) %>%
    ungroup()

  write_rds(fao_capture, file = here("data", "fao", "fao-capture.rds"))


} else {
  fao_capture <-
    read_rds(file = here("data", "fao", "fao-capture.rds"))


}

# get FAO shapefile

if (!dir.exists(here("data", "FAO_AREAS_NOCOASTLINE"))) {
  download.file(url = "http://www.fao.org/figis/geoserver/area/ows?service=WFS&request=GetFeature&version=1.0.0&typeName=area:FAO_AREAS_NOCOASTLINE&outputFormat=SHAPE-ZIP",
                destfile = here("data", "FAO_AREAS_NOCOASTLINE.zip"),
                      mode = "wb"
)
  
  unzip(
    here("data", "FAO_AREAS_NOCOASTLINE.zip"),
    exdir = here("data", "FAO_AREAS_NOCOASTLINE")
  )
  
}


fao_areas <- sf::st_read(here('data', "FAO_AREAS_NOCOASTLINE")) %>%
  janitor::clean_names()

fao_areas <- fao_areas %>%
  group_by(f_area) %>%
  nest() %>%
  mutate(geometry = map(data, sf::st_union)) %>%
  select(-data)


fao_areas = fao_areas %>%
  unnest(cols = geometry) %>%
  ungroup() %>%
  sf::st_as_sf() %>%
  # sf::st_simplify() %>%
  mutate(fao_area_code = as.numeric(f_area)) #%>% 
  # st_transform(crs = "+proj=moll")
  # 
  ggplot(fao_areas) +
    geom_sf()

##SELECT SCENARIO --- there are four scenarios
scenario<-"BAU1"
#scenario<-"OAconstant"
#scenario<-"EBvK01fin"
#scenario<-"all managed"

#Load MOLLWEIDE projected data
MegaData<-readRDS(file = here("data","MegaData.rds"))
Cleanmegacell<-readRDS(file = here("data","Cleanmegacell_mollweide.rds"))
CleanCoordmegacell<-readRDS(file = here("data","CleanCoordmegacell_mollweide.rds"))
KprotectedPerCell_Library<-readRDS(file = here("data","KprotectedPerCell_Library_mollweide.rds"))
MPA_coord<-readRDS(file= here("data","MPA_coord_mollweide.rds")) #this is my code
land_shp_moll<-readRDS(file = here("data","land_shp_moll.rds"))
head(MPA_coord)
dim(MPA_coord)

#get MPA positions
CleanCoordmegacell_MPA<-left_join(CleanCoordmegacell,MPA_coord,by=c("lon","lat"))
head(CleanCoordmegacell_MPA)
dim(CleanCoordmegacell_MPA)
sum(CleanCoordmegacell_MPA$MPA,na.rm=T)

#positions of 1s (MPAs)
MPAposition<-which(CleanCoordmegacell_MPA$MPA==1)
head(MPAposition)
length(MPAposition)#2931 --- 2.44% are MPAs
length(MPAposition)*100/dim(Cleanmegacell)[1]

##TRY new approach
numcell<-dim(Cleanmegacell)[1]
celltoiterateFULL<-1:numcell
MPAselect0<-matrix(0, nrow=numcell, ncol=1)
PriorityAreas<-c()
NetworkResult<-vector()

#Make MPAselect0==1 for MPAs
MPAselect0[MPAposition]<-1
head(MPAselect0)
sum(MPAselect0)

#remove MPAs from celltoiterateFULL
celltoiterateFULL<-celltoiterateFULL[-MPAposition]
celltoiterate<-celltoiterateFULL
ncell<-length(celltoiterate)

###Compute spillover---PIXEL-LEVEL spillover 
K<-MegaData$Kfin # K per species
m<-MegaData$m # mobility per species
r<-MegaData$r

if (scenario=="all managed"){
  E<-MegaData$Emsy
}else if(scenario=="OAconstant"){
  E<-MegaData$Efin
}else if(scenario=="BAU1"){  
  E<-MegaData$Efin_BAU1
}else if(scenario=="Efin_msy"){ 
  E<-MegaData$Efin_msy
}else if(scenario=="EBvK01fin"){ 
  E<-MegaData$EBvK01fin 
}

ER<-1-E
ER<-1*(ER>1) + ER*(ER<=1)
max(ER)
min(ER)

MPAselect<-MPAselect0
R<-rowSums(KprotectedPerCell_Library[,which(MPAselect==1),drop=FALSE])
ER_redistribute<-1-(1-ER)^(1/(1-R))


b_outside_bau <-
  ((m * K * (1 - R)) / (ER_redistribute * R + m)) * (1 - (ER_redistribute * (1 - R) * m) /
                                                       ((ER_redistribute + m) * r)) 

hbau<-na.omit(ER_redistribute*((m*K*(1-R))/((ER_redistribute*R)+m))*(1-((ER_redistribute*(1-R)*m)/(((ER_redistribute*R)+m)*r))))
hbau<-hbau*(hbau>0)
HBAU<-sum(hbau)
HBAU

PICKSIZE<-100 #number of MPA sites selected

nmax<-floor(length(celltoiterate)/PICKSIZE)
nmax #this is the number of iterations needed for PICKSIZE at a time!

Eevolve<-matrix(nrow=nmax,ncol=dim(MegaData)[1])
# k_per_cell <- t(as.datKprotectedPerCell_Library)

if (run_cabral_et_al){
  
  cores<-detectCores() - 2
registerDoParallel(cores)
for (i in 1:nmax){ 
  MPAselectPrev<-rowSums(KprotectedPerCell_Library[,which(MPAselect0==1),drop=FALSE])
  a <- Sys.time()
  result <- foreach(iter = 1:length(celltoiterate), .combine = rbind) %dopar% {
    MPAselect<-MPAselect0
    MPAselect[celltoiterate[iter]]<-1
    R<-MPAselectPrev+KprotectedPerCell_Library[,celltoiterate[iter]]
    ER_redistribute<-1-(1-ER)^(1/(1-R))
    
    
    hmpa<-na.omit(ER_redistribute*((m*K*(1-R))/((ER_redistribute*R)+m))*(1-((ER_redistribute*(1-R)*m)/(((ER_redistribute*R)+m)*r))))
    hmpa<-hmpa*(hmpa>0)
    HMPA<-sum(hmpa)
    HMPA-HBAU
  }
  Sys.time() - a
  
  #1. find the location of the top 1000 highest pixel-level
  myorderHightoLow<-order(-result)#positions
  cellselected<-myorderHightoLow[1:PICKSIZE] #but these are the position of the temporary pixels, not our reference pixels
  #convert coord to scale comparable to priority areas
  Prioritycellselected<-celltoiterate[cellselected]
  
  #3. block those additional 100 in MPAselect
  MPAselect0[Prioritycellselected]<-1
  
  #4. save them for our priority areas
  PriorityAreas<-append(PriorityAreas,Prioritycellselected)
  
  #5. Calculate food prov of the additional 100 cells
  MPAselect<-MPAselect0
  R<-rowSums(KprotectedPerCell_Library[,which(MPAselect==1),drop=FALSE])
  ER_redistribute<-1-(1-ER)^(1/(1-R))

  hmpa<-na.omit(ER_redistribute*((m*K*(1-R))/((ER_redistribute*R)+m))*(1-((ER_redistribute*(1-R)*m)/(((ER_redistribute*R)+m)*r))))
  hmpa<-hmpa*(hmpa>0)
  HMPA<-sum(hmpa)
  
  #save result. Comment other parts not needed now.
  NetworkResult[i]<-HMPA-HBAU
  Eevolve[i,]<-ER_redistribute
  
  #pass this to the top
  celltoiterate<-celltoiterateFULL[!celltoiterateFULL %in% PriorityAreas]#celltoiterateFULL[-PriorityAreas]#bacause Prioritycellselected are real numbers, not rank
  
  print(c(i,NetworkResult[i]))
  rm(result,myorderHightoLow,cellselected,Prioritycellselected, MPAselect,R,hmpa,HMPA)
}
plot(NetworkResult)
stopImplicitCluster()

if(scenario=="BAU1"){
  saveRDS(NetworkResult,file = file.path(results_path,"NetworkResult100_BAU1_mollweide.rds"))
  saveRDS(PriorityAreas,file = file.path(results_path, "PriorityAreas100_BAU1_mollweide.rds"))
}else if(scenario=="all managed"){  
  saveRDS(NetworkResult,file = "~/foodGCEfile/NetworkResult100_allmanaged_redistribute.rds")
  saveRDS(PriorityAreas,file = "~/foodGCEfile/PriorityAreas100_allmanaged_redistribute.rds") 
}else if(scenario=="OAconstant"){
  saveRDS(NetworkResult,file = "~/foodGCEfile/NetworkResult100_OAconstant_mollweide_redistribute.rds")
  saveRDS(PriorityAreas,file = "~/foodGCEfile/PriorityAreas100_OAconstant_mollweide_redistribute.rds")   
}else if(scenario=="EBvK01fin"){
  saveRDS(NetworkResult,file = "~/foodGCEfile/NetworkResult100_EBvK01fin_mollweide_redistribute.rds")
  saveRDS(PriorityAreas,file = "~/foodGCEfile/PriorityAreas100_EBvK01fin_mollweide_redistribute.rds") 
}

  
} else {
  
  NetworkResult <-readRDS(file = file.path(results_path,"NetworkResult100_BAU1_mollweide.rds"))
  
  PriorityAreas <- readRDS(file = file.path(results_path,"PriorityAreas100_BAU1_mollweide.rds") )
  
}

PICKSIZE<-100
BenefitCurve<-as.data.frame(NetworkResult)/1000000
MPAsize<-(length(MPAposition)+1)*100/dim(Cleanmegacell)[1]
#(MPAinEEZ+1)*100/length(EEZposition)#there is +1 because the next pixel starts with +1
BenefitCurve$MPA <- rescale(seq.int(nmax), to = c(MPAsize, 100))
zerozero<-data.frame(0,0)
names(zerozero)<-c("NetworkResult","MPA")
zerozero[1,]<-c(-HBAU/(1000000),100)
BenefitCurve<-rbind(BenefitCurve,zerozero)
theme_set(theme_cowplot())
benefitplot<-ggplot(BenefitCurve, aes(MPA, NetworkResult)) +geom_line(col="blue")+# theme_classic()+
  labs(x="% EEZ protected",y="Change in catch (MMT)",title=paste("Global (max =", round(max(BenefitCurve$NetworkResult),2),"MMT)"))#+geom_hline(yintercept = 0)
benefitplot

Priority<-as.data.frame(PriorityAreas)
Priority$rank <- ((seq.int(nrow(Priority))/ncell))*100

#add dh
NetworkResult_prime<-as.data.frame(NetworkResult)
dH_prime<-NetworkResult_prime %>% mutate(dH = NetworkResult - lag(NetworkResult, default = 0))
plot(dH_prime$dH)
Priority$NetworkResult<-rep(NetworkResult, each=PICKSIZE) ## this is adding delta H
Priority$dH<-rep(dH_prime$dH/PICKSIZE, each=PICKSIZE) ## this is adding delta H
head(Priority)
dim(Priority)

PriorityFrame <- as.data.frame(seq.int(nrow(CleanCoordmegacell)))
names(PriorityFrame) <- "PriorityAreas"
#add the priority
PriorityFrame2<-left_join(PriorityFrame,Priority, by="PriorityAreas")
PriorityFrame2[is.na(PriorityFrame2)] <- 0
head(PriorityFrame2)
dim(PriorityFrame2)

ShortCoord<-CleanCoordmegacell
ShortCoord$rank<-PriorityFrame2$rank
ShortCoord$NetworkResult<- PriorityFrame2$NetworkResult#this is for deriving dh
ShortCoord$dH<- PriorityFrame2$dH#this is for deriving dh
ShortCoord$ID<-row.names(ShortCoord)

dim(ShortCoord)
head(ShortCoord)

ShortCoord_Sort <- ShortCoord[order(-ShortCoord$rank),] %>% filter(rank!=-1000)

ShortCoord_Sort$sign<-ShortCoord_Sort$dH>0
InflectPoint<-min(which(ShortCoord_Sort$sign == TRUE))
InflectMPA<-ShortCoord_Sort$rank[InflectPoint]

MPAcoverage<-ShortCoord_Sort %>% ggplot(aes(x=lon,y=lat,fill=rank)) + #scale_fill_gradient2(low="darkred", mid="white",high="#00539CFF",midpoint = 0, space = "Lab",na.value = "grey50", guide = "colourbar", aesthetics = "fill",name=expression(paste(Delta, "H (MT)")))+
  scale_fill_gradientn(colours = c("forestgreen", "white", "orange"), limits=c(0,100), values = scales::rescale(c(min(ShortCoord_Sort$rank), InflectMPA, max(ShortCoord_Sort$rank))),name="Protection sequence")+
  theme(axis.title.x = element_blank(),axis.title.y = element_blank(), panel.background = element_blank(),legend.position=c(0.63, 0.05), legend.direction = "horizontal")+ #"bottom
  geom_raster()+
  geom_raster(data=MPA_coord, aes(x=lon, y=lat),fill="cyan")+  #"#EEA47FFF"
  geom_sf(data = land_shp_moll, fill="black", lwd = 0, inherit.aes = F)+ theme(panel.grid.major = element_line(colour = 'transparent'))
MPAcoverage

```



# Summary

Cabral et al. 2020 presents a global network of MPAs designed to maximize food production. To be clear, we believe that MPAs are an important part of the marine management toolbox, and in the right context can provide conservation and fishery benefits. We also do not dispute that properly designed MPAs may improve fishery yields in overfished fisheries. We agree that given the large size but low fishery catches of the world's open-oceans, one could likely close off of large portion of the world's oceans at minimal loss to global catch (though potentially with large distribution and equity impacts). Lastly we agree that given no other information, targeting areas where a) species probably live and b) those species are more likely to be overfished under BAU is likely a good strategy for identifying areas where MPAs may be able to benefit fisheries. 

However, none of these general insights require explicit modeling. Our concern is that the the model used in Cabral et al. 2020 overstates the confidence that readers should have in the exact magnitude of benefits of costs, and in the size and placement of food maximizing MPAs. We summarize our reasons for this here, in particular that 

1. Using species distribution models (SDMs) from Aquamaps as a proxy for both the extent and relative abundance in space of species is unrealistic and dramatically positively biases estimates of MPA size for unassessed stocks when applied to the physical globe. 

2. The roughly non-spatial nature of the operating model itself removes any consideration of distance, and requires the assumption that fishing mortality is evenly distributed across fishable areas. This allows MPAs to produce benefits across vast distances (e.g. MPAs in the Caribbean benefiting stocks off of China), even when placed in areas where best available data suggests fishing pressure is negligible under BAU. This is likely to positively bias the optimal size and estimated benefits of MPA networks, particularly if MPAs are clustered in space and isolated stocks are spatially separated within the broader Aquamaps layer. 

3. Evaluation of the models predictions for RAM stocks alone produces some questionable results, namely that most RAM stocks, which collectively produce roughly 50% of global captures, could have over 25% of their footprint covered in MPAs while actually increasing captures from these stocks. We also have some questions about the BAU policy as applied to RAM stocks, which if we are interpreting things correctly do not appear to be correct

While we believe that some of the key assumptions made here, along with others we are happy to discuss, generally act to positively bias estimates of physical food-optimal MPA size, it is entirely possible that other assumptions could be negatively biasing estimates. The key point here though is that reasonable people working with another set of equally plausible assumptions could easily reach vastly different conclusions to the specific results presented here. [Ovando 2018 Fig 3.15](https://danovando.github.io/dissertation/zissou.html#results-1) demonstrates that, as shown here and in many other simulation papers, when stocks are overfished, an MPA on the order of 20-40% (and bigger if things are really overfished) increase yields. However, those results also showed that within those general rules of thumb the actual outcomes of the MPA can vary wildly depending on characteristics of fleet dynamics, movement, and density dependence. A large body of simulation papers have shown that MPAs can be good, bad, or in between for fisheries depending on a host of assumptions, some relatively straightforward (must be overfished in the absence of an MPA), and others much less so (being able to accurately measure the nature of dispersal at different life stages relative to MPA size). We suggest that we have come as far as we can with simulation based results in our understanding of the global role of MPAs in food security. It is time to focus our efforts on empirically evaluating the observed fishery impacts of MPAs, to put the wide range of theoretical predictions made over the years to the test. 


# Where's the MSY?


```{r}

msyframe <- matrix(rep(MegaData$MSYfin, ncol(KprotectedPerCell_Library)), nrow = length(MegaData$Kfin), ncol = ncol(KprotectedPerCell_Library))

msy_per_cell <- colSums(KprotectedPerCell_Library * msyframe)

tmp <- ShortCoord %>% 
  mutate(msy_per_cell = msy_per_cell) %>% 
    sf::st_as_sf(coords = c("lon", "lat"),
               crs = sf::st_crs(land_shp_moll)) 

tmp %>% 
  ggplot(aes(color = msy_per_cell)) + 
    geom_sf(data = land_shp_moll, fill="black", lwd = 0, inherit.aes = F)+ theme(panel.grid.major = element_line(colour = 'transparent')) +
  geom_sf(size = .1) + 
  scale_color_viridis_c()

cumu <- tibble(msy_per_cell = msy_per_cell) %>% 
  arrange(desc(msy_per_cell)) %>% 
  mutate(cumulative_msy = cumsum(msy_per_cell)) %>% 
  mutate(patch = 1:nrow(.)) %>% 
  mutate(ppatch = patch / nrow(.))

cumu %>% 
  ggplot(aes(ppatch, cumulative_msy)) + 
  geom_line() + 
  scale_x_continuous(labels = percent, name = "% of Patches") + 
  scale_y_continuous(labels = comma, name = "Cumulative MSY")


eezs <-
  sf::read_sf(here("data", "World_EEZ_v11_20191118_LR", "eez_v11_lowres.shp")) %>%
  mutate(iso3_code = countrycode(SOVEREIGN1, "country.name",  "iso3c")) %>% 
    mutate(iso3c_name = countrycode(iso3_code, "iso3c",  "country.name")) %>%
  filter(!is.na(iso3_code)) %>%
  sf::st_transform(sf::st_crs(land_shp_moll))

a = eezs %>% 
  filter(ISO_TER1 == "CHN") %>% 
  ggplot() +
  geom_sf(fill = "red") + 
  geom_sf(data = land_shp_moll, fill="black", lwd = 0, inherit.aes = F)+ theme(panel.grid.major = element_line(colour = 'transparent'))

# ggsave("test.png", a)


bau_mpas <- ShortCoord_Sort %>%
  sf::st_as_sf(coords = c("lon", "lat"),
               crs = sf::st_crs(land_shp_moll)) 

fao_country_captures <- fao_capture %>% 
  filter(capture_units == "t",
         !str_detect(fao_area,"Inland waters")) %>% 
  group_by(country_name_en, iso3_code) %>% 
  filter(year == max(year)) %>% 
  summarise(capture = sum(capture, na.rm = TRUE)) %>% 
  arrange(desc(capture)) %>% 
  ungroup() %>% 
  mutate(capture_rank = percent_rank(capture)) %>% 
  arrange(desc(capture_rank)) %>% 
  mutate(cumu_capture = cumsum(capture)) %>% 
  mutate(first_half = cumu_capture < (max(cumu_capture) / 2),
         p_global_h = capture / max(cumu_capture))


test <- sf::st_join(bau_mpas, eezs)

# MSY and sign per EEZ

spatial_msy <- tmp %>%
  sf::st_join(eezs) %>%
  filter(!is.na(iso3_code)) %>% 
  janitor::clean_names()

mean(spatial_msy$d_h > 0)

spatial_msy %>% 
  filter(!is.na(iso3c_name) & iso3c_name == "China") %>% 
  ggplot(aes(color = d_h)) + 
  geom_sf(show.legend = FALSE) + 
  geom_sf(data = land_shp_moll, fill="black", lwd = 0, inherit.aes = F)+ theme(panel.grid.major = element_line(colour = 'transparent'))


spatial_msy %>% 
  ggplot(aes(color = d_h)) + 
  geom_sf(show.legend = FALSE) + 
  geom_sf(data = land_shp_moll, fill="black", lwd = 0, inherit.aes = F)+ theme(panel.grid.major = element_line(colour = 'transparent')) + 
  scale_color_viridis_c()

p_eez_closed <- spatial_msy %>%
  group_by(iso3c_name, iso3_code) %>%
  summarise(
    p_closed = mean(d_h > 0),
    weighed_p_closed = weighted.mean(d_h > 0, w = msy_per_cell),
    top_weighed_p_closed = weighted.mean(d_h > 0 &
                                           rank < 5, w = msy_per_cell),
    top_p_closed = mean(d_h > 0 & rank < 5)
  ) %>%
  arrange(desc(p_closed)) %>%
  left_join(fao_country_captures, by = c("iso3_code" = "iso3_code")) %>%
  ungroup()
  

p_eez_closed_map <- p_eez_closed %>%
  ggplot(aes(color = p_closed)) +
  geom_sf(
    data = land_shp_moll,
    fill = "black",
    lwd = 0,
    inherit.aes = F
  ) + theme(panel.grid.major = element_line(colour = 'transparent')) +
  geom_sf(size = .1) +
  scale_color_viridis_c(labels = percent, name = "% of EEZ in food increasing MPA", guide = guide_colorbar(barwidth = unit(15,"lines"))) + 
  theme(legend.position = "top", legend.direction = "horizontal")


top_p_eez_closed_map <- p_eez_closed %>%
  ggplot(aes(color = top_p_closed)) +
  geom_sf(
    data = land_shp_moll,
    fill = "black",
    lwd = 0,
    inherit.aes = F
  ) + theme(panel.grid.major = element_line(colour = 'transparent')) +
  geom_sf(size = .1) +
  scale_color_viridis_c(labels = percent, name = "% of EEZ in food increasing MPA", guide = guide_colorbar(barwidth = unit(15,"lines"))) + 
  theme(legend.position = "top", legend.direction = "horizontal")


weighted_p_eez_closed_map <- p_eez_closed %>%
  ggplot(aes(color = weighed_p_closed)) +
  geom_sf(
    data = land_shp_moll,
    fill = "black",
    lwd = 0,
    inherit.aes = F
  ) + theme(panel.grid.major = element_line(colour = 'transparent')) +
  geom_sf(size = .1) +
  scale_color_viridis_c(labels = percent, name = "% of K-weighted EEZ in food increasing MPA", guide = guide_colorbar(barwidth = unit(15,"lines"))) + 
  theme(legend.position = "top", legend.direction = "horizontal")


p_eez_closed_plot <- p_eez_closed %>% 
  # filter(cumu_capture < 60e6) %>% 
  filter(capture_rank > 0.85) %>% 
  ggplot(aes(reorder(iso3c_name,p_closed), p_closed, fill = capture)) + 
  geom_col() + 
  coord_flip() + 
  scale_y_continuous(labels = percent, name =  "% of EEZ in food increasing MPA") + 
  scale_x_discrete(name = '') + 
  scale_fill_viridis_c(labels = comma)

top_p_eez_closed_plot <- p_eez_closed %>% 
  # filter(cumu_capture < 60e6) %>% 
  filter(capture_rank > 0.85) %>% 
  ggplot(aes(reorder(iso3c_name,top_p_closed), top_p_closed, fill = capture)) + 
  geom_col() + 
  coord_flip() + 
  scale_y_continuous(labels = percent, name =  "% of EEZ in food increasing MPA") + 
  scale_x_discrete(name = '') + 
  scale_fill_viridis_c(labels = comma)

# p_eez_closed_plot + top_p_eez_closed_plot

weighted_p_eez_closed_plot <- p_eez_closed %>%
  # filter(cumu_capture < 60e6) %>%
  filter(capture_rank > 0.85) %>%
  ggplot(aes(reorder(iso3c_name, capture), weighed_p_closed, fill = capture)) +
  geom_col() +
  coord_flip() +
  scale_y_continuous(labels = percent, name =  "% of EEZ in food increasing MPA") +
  scale_x_discrete(name = '')


a = spatial_msy %>% 
  group_by(iso3c_name) %>% 
  arrange(desc(msy_per_cell)) %>% 
  mutate(cumu_msy =cumsum(msy_per_cell)) %>% 
  mutate(patch = 1:length(cumu_msy)) %>% 
  mutate(ppatch = patch / length(cumu_msy)) %>% 
  ungroup() %>% 
  group_by(iso3c_name) %>% 
  mutate(total_msy = max(cumu_msy)) %>% 
  ungroup()


cumu_msy_country_plot <- a %>% 
  ggplot(aes(ppatch, cumu_msy, color =total_msy)) + 
  geom_line() +
  facet_wrap(~iso3c_name, scales = "free_y") + 
  theme_light() + 
  theme(axis.text = element_blank(),
        strip.text = element_blank()) + 
  scale_x_continuous(name = "% of Patches") + 
  scale_y_continuous(name = "Cumulative MSY") + 
  labs(caption = "each facet is a country") + 
  scale_color_viridis_c(trans = "log10")

```


# Lack of Explicit Distance has Important Implications

In terms of the actual calculations of effect of MPAs on on harvest, there is no explicit space in the model, beyond essentially a two-patch system with a single carrying capacity, K, and movement in each patch a function of MPA size. So, this means that for any individual stock, the food maximizing MPA size is simply a function of life history and the assumption about BAU conditions: A stock with F/F~MSY~ BAU of 1.5 will need a much bigger MPA than one with  F/F~MSY~ BAU of 1, and a stock with  F/F~MSY~ BAU of 0.5 should maintain or lose catch from any MPA under these assumptions. So, without any spatial mapping, one could, taking the Costello et al. 2016 estimates of BAU stock status as given, as well as the assumptions of this model, calculate the optimal percent of each stock's K that should be in an MPA to maximize food. 

The issues comes in then in trying to translate that *percent* protected onto a physical map of the world. By our understanding, the assumption for any unassessed stocks is that the stock range is equal to the range in Aquamaps (removing overlapping range with any RAM stocks of the same species). Looking at largehead hairtail (*Trichiurus lepturus*) as an example, the stock spans the entire globe (Fig.\@ref(fig:lht-plot)). Translating from the stylized surplus production model to the globe then requires a few critical assumptions. Namely:

1. Probability of occurrence from aquamaps is proportional to biomass (K)

2. Fishing mortality is equally and instantaneously distributed across all fishable patches

3. Density dependence / growth / recruitment occurs at the global level, and is distributed inside and outside MPA in proportion to total K inside / outside.  

4. Calculated movement is evenly distributed across all MPA and non-MPA areas in each time step. 

One could make a case for any one of these assumptions, but there are several features of the data used and the results produced that suggest to us these assumptions produce suspect results. 

In terms of the food maximizing, clearly the assumption about the connectivity of these systems matter. Consider a hypothetical scenario where there are two completely separate stocks of largehead hairtail, one that lives in the Pacific and Indian Oceans, and the other in the Atlantic. Suppose then that F/Fmsy is 2 in the Pacific/Indian Ocean and F/Fmsy = 1 in the Atlantic (and assume that both have equal total K and MSY). What would be the consequences of closing off the Atlantic inside an MPA for food production of largehead hairtail? Assuming no connectivity between the Atlantic and Pacific stocks, the Pacific/Indian Ocean stock would be driven to collapse (assuming Schaefer dynamics), and the Atlantic stock would rebuild to carrying capacity. The MPA would cause a loss relative to BAU equal to the MSY of the Atlantic stock in food production. 

But, what if in reality the Atlantic and Pacific are one shared stock in the manner described in Cabral et al. 2020? Closing of the Atlantic inside an MPA might well then provide substantial food benefits, to the extent that the Atlantic MPA brings the biomass weighted mean fishing mortality rate of the total stock in line with Fmsy; i.e., you can still fish like crazy in the Pacific / Indian Ocean, but it is now being bolstered by spillover from the Atlantic MPA. Clearly  then, decisions about how to aggregate stocks play a major role in what an global network of MPAs for food would look like as we move from the stylized two-patch model to an actual map of the world. 

While questions about the "right" boundary of a stock are always difficult and nebulous, we have concerns about the practical implications of some of the choices made here, mostly related to the realism and consequences of the assumptions required to produce the main results of Cabral et al. 2020. We detail some specific concerns with the use of AquaMaps as both an index of spatial abundance and as a marker for a shared biological stock, and then examine two case study results that we feel illustrate the issues with mapping the percentage based outcomes of the model onto the actual locations of the world. 


```{r lht-plot, fig.cap = "Range of largehead hairtail (*Trichiurus lepturus*) in KprotectedPerCell_Library"}
tmp <- ShortCoord %>% 
  mutate(k_per_cell = as.numeric(KprotectedPerCell_Library[which(MegaData$SciName == "Trichiurus lepturus")[1],])) %>% 
    sf::st_as_sf(coords = c("lon", "lat"),
               crs = sf::st_crs(land_shp_moll)) %>% 
  filter(k_per_cell > 0) 

tmp %>% 
  ggplot(aes(color = k_per_cell)) + 
    geom_sf(data = land_shp_moll, fill="black", lwd = 0, inherit.aes = F)+ theme(panel.grid.major = element_line(colour = 'transparent')) +
  geom_sf(size = .1) + 
  scale_color_viridis_c()

```

# Aqauamaps as an Index of Biomass

Designing an MPA network for any objective clearly requires some knowledge of the spatial distribution of the stock, as well as the movement rates of organisms within that spatial distribution. Both of these are also poorly understood for many species, and so we appreciate the need for the simplifying assumptions made here. However, we feel that there are some substantial issues with treating the species distribution model (SDM) from AquaMaps as both an index of the relative biomass in space, and as a measure of the range of the connected biological stock.

Cabral et al. 2020 uses species distribution data from Aquamaps (aquamaps.org) to define the ranges of species in the analysis. Aquamaps was designed as a presence-only, environmental envelope model that enables “mass-production of predicted distributional ranges of marine organisms from global occurrence databases, using simple and pre-defined numerical descriptions of species–habitat relationships”(https://doi.org/10.1016/j.ecolmodel.2009.10.025). The stated goal of Aquamaps is to provide “maximum output of standardized species range maps at the global scale.”

The way that Aquamaps models do this is by applying simple rules to define the environmental ranges of species’ preferences for specific temperatures, salinities, and primary productivity (and, for polar species, sea ice concentration). For each species and each environmental variable, an “environmental envelope” is defined as a trapezoidal probability of occurrence across the range of the variable (see Fig.\@ref(fig:aquamaps)). Between the 10th and 90th percentile of observed variation in an environmental parameter (at species presence points), the species is considered maximally likely to occur. Then, the overall map for each species is constructed by combining probabilities across the environmental variables with multiplication. The probability of occurrence for a species in each 0.5 degree x 0.5 degree spatial cell across the globe is,

$$P_c=P_{depth} *P_{temperature}*P_{salinity}$$


```{r aquamaps, fig.cap="Diagram of Aquamaps SDM process"}
knitr::include_graphics(here("imgs","aquamaps-trap.png"))
```


Each species’ map is constructed by overlaying these simple environmental affinities and extracting their product. There is no interaction among environmental variables and no statistical modeling beyond extraction of the empirical distribution of occurrence records across environmental predictors (i.e., there is no “fitting” of the model as would be the case with, say, Generalized Additive Models a la [SOME REFERENCE]). Moreover, there is no treatment of abundance or uncertainty. For example, there is no weighting of data based on the number of observed occurrences in each cell, and no statistical model describing abundance given presence.

As mentioned above, these methods for Aquamaps were specifically chosen to err on the side of positive bias in species presence, because they are meant (primarily) as the basis for analyses describing global patterns of marine biodiversity. However, the approach has serious implications when used to extrapolate fish abundance across space, as in the Cabral et al. analysis. The trapezoidal shape of environmental affinities is specifically designed for maximum coverage, and will naturally result in inflated ranges of high species occurrence probability. It means, for example, that a spatial cell that is in the 10th percentile of a species’ tolerance for depth, temperature, and salinity will be treated exactly the same as a cell at the 50th percentile of these values. Because the Cabral et al. analysis extrapolates the Aquamaps ranges to abundance by combining them with modeled carrying capacity, it follows that the abundance of each species will be distributed homogeneously across a wide swath of ocean.

The natural outcome of assuming such homogeneity of a species distribution across space is that each exploited species, and particularly the species for which more rigorously-defined RAM stock distributions are unavailable, will have large portions of its assumed range where either a) MPAs can be placed, or b) fishing can occur, where assumed species abundance is artificially inflated from reality. Essentially, there is much more spatial scope for “trading” of species between open and closed areas than there should be, making tradeoffs more forgiving between closing areas to fishing and gaining fisheries productivity elsewhere. 

We understand that simplifying assumptions must be made in efforts to make global assessments, and we do not know of a better global model of species distributions that could be used off the shelf. However, based off the structural assumptions of AquaMaps, it appears likely that using Aquamaps as an index of abundance will positively bias the assumed stock range used in Cabral et al. 2020. Moreover, this approach does not account for physical barriers to connectivity that would also reduce the effective stock size (e.g., Fig.\@ref(fig:lht-plot) would assume that growth and movement from say those small patches in the mid-Atlantic are just as connected to China as patches off of Japan). 

To consider the potential magnitude of this footprint bias, we can compare the size of the stock footprint for the RAM stocks used in Cabral et al. 2020, which use the spatial footprints created by Chris Free for each of the RAM stocks, to those for the "unassessed" stocks that use the Aquamaps SDM as the footprint (less any RAM stocks for the same species). While the RAM footprints are not definitive, they provide a sense of what experts have judged to be the range of a connected biological stock. 

Cabral et al. 2020 assumes that proportion of K is proportional to the Aquamaps SDM. So, rather than simply summing the number of cells with "K" > 0 for each species, we calculate a K-weighted footprint as 

$$footprint_s = \sum_{i=1}^I\frac{k_{i,s}}{max(\pmb{k_s})} $$

where *k* is the "carrying capacity" for species *s* in cell *i* from KprotectedPerCell_Library. So, for a species where $k_i$ is equal in every patch footprint will equal the number of cells. But, if a k is much bigger in some patches than others, the k-weighted footprint will be smaller. Implementing this measure shows that there are stark differences between these two footprints: the median unassessed fishery has a k-weighted footprint roughly 17 times greater than the median RAM stock, with many unassessed stocks having order of magnitude greater spatial footprints than RAM stocks (Fig/\@ref(fig:footprint)). 


```{r footprint, fig.cap = "Comparison of K-weighted footprint size between unassessed and RAM stocks. K-weighted footprint = sum(k_(i,s) / max(k_s)) where *i* denotes cell and *s* denotes species A) Distribution of individual stocks B) difference in median footprint size"}
MegaData<-readRDS(file = here("data","MegaData.rds")) %>% 
  janitor::clean_names()

KprotectedPerCell_Library <-
  readRDS(file = here("data","KprotectedPerCell_Library_mollweide.rds"))

footprint <- as.data.table(KprotectedPerCell_Library)

tmp <- ShortCoord %>% 
  mutate(k_per_cell = as.numeric(KprotectedPerCell_Library[1,])) %>% 
    sf::st_as_sf(coords = c("lon", "lat"),
               crs = sf::st_crs(land_shp_moll)) %>% 
  filter(k_per_cell > 0) 


# a really rough measure of footprint is just the number of positive cells

raw_footprint <- rowSums(footprint > 0)

foo <- function(x){
  y = x / max(x)
}

k_footprint <-  colSums(apply(footprint,1,foo)) # colsums since for some reason this flips things 

# k footprint is a measure of how concentrated the population is. If every cell has the same k, then k_footprint == raw_footprint. But, if 99.9% of K is in 1 cell and the rest is in 1000 other cells, K footprint will be small


footprint <- MegaData %>% 
  select(sci_name, manage) %>% 
  mutate(footprint = raw_footprint,
         k_footprint = k_footprint)

# footprint %>% 
#   ggplot(aes(footprint, fill = manage == 1)) + 
#   geom_density() + 
#   scale_x_log10(name = "Footprint Size (note log 10)")


foot_dist_plot <- footprint %>% 
  ggplot(aes(k_footprint, fill = manage == 1)) + 
  geom_density(alpha = 0.75) + 
  scale_x_log10(name = "K Footprint Size (note log 10)") + 
  scale_fill_discrete(name = "", labels = c("Unassessed","RAM")) + 
  theme(legend.position = "top")

foot_delta_plot <- footprint %>% 
  group_by(manage) %>% 
  summarise(median_k_footprint = median(k_footprint),
            mean_k_footprint = mean(k_footprint)) %>% 
  ggplot(aes(manage == 1, median_k_footprint)) + 
  geom_col() +
  scale_x_discrete( labels = c("Unassessed","RAM"), name = '') + 
  scale_y_continuous(name = "Median K Footprint")


foot_dist_plot + foot_delta_plot + plot_annotation(tag_levels = 'A')

# 


# now, load in the protected thingy and try and calculate the actual area protected in each step, and then plot the percent of each stocks footprint protected globally


#   complete_network_result <- readRDS(file = file.path(results_path,"NetworkResult100_BAU1_mollweide.rds"))
#  
#   complete_priority_areas <-  readRDS(file = file.path(results_path,"PriorityAreas100_BAU1_mollweide.rds"))  
# 
# plot(complete_network_result)
# 
# # assuming that this is just in number of cells then, for each stock's footprint, express inflection points as percent of footprint
# 
# 
# head(footprint)
# 
# 
# footprint <- footprint %>% 
#   mutate(five_percent = (0.05 * length(complete_priority_areas)) / k_footprint,
#          twenty_five_percent = (0.25 * length(complete_priority_areas)) / k_footprint)
# 
# footprint %>% 
#   ggplot(aes(five_percent, fill = manage == 1)) + 
#   geom_histogram() + 
#   scale_x_log10()
  
```

This clearly has large practical implications. It is possible that unassessed species, being more tropical than the average RAM stock, have a greater species footprint than RAM stocks, but it seems much more likely that this stark difference is an artifact of the use of Aquamaps. Practically then, since the model itself works in percentages, an unassesssed stock and a RAM stock with the same life history, k roughly equal in each patch ,and BAU fishing pressure would have the same optimal MPA size for food provision as percent of range, but the unassessed stock might be expected to have an MPA network 17X larger than the RAM stock when applied to the global map. Note that this result does not factor in the distance that larvae or fish must traverse between patches, which the Aquamaps distributions seem to produce (relative to the relatively contiguous RAM distributions). 

The total area protected to maximize food production from Cabral is a function of both the optimal percent size MPA of individual species and the degree of habitat overlap across species. Given that fewer species live in the high seas, and both the RAM and unassessed stocks that do live there are likely to have very large footprints (though the RAM stocks in those areas are mostly not overfished, so there would be few benefits from MPAs), it is likely that even accounting for this size bias, similar portions of the high seas could be closed at little cost to total food production. However, for species that primarily inhabit coastal areas, the fact that all else being equal the model will create much larger MPAs, in terms of absolute area protected on the map, for unassessed than assessed stocks, and since unassessed stocks from Costello et al. estimates will have lower BAU stock status, these results are likely-and greatly- overestimating the total amount of coastal area in a food-maximizing MPA network. 

# Case Study - Chinese Fisheries

Let's consider some of the implications of the spatial modeling choices with a case study. We first selected all unassessed species classified as overfished under BAU for which 90% or more of the catch comes from inside FAO area 61 - the Pacific NorthWest, made up mostly of catches from China, along with Japan and South Korea. As we might hope, the cells with the highest individual K values come from within area 61. However, according to aquamaps these case study stocks have a nontrivial portion of their range in areas quite far from the Pacific Northwest, including throughout the Mediterranean (Fig.\@ref(fig:of-61))

```{r of-61, fig.cap = "Distribution of aquamaps derived K for stocks with 90% or more of their catch reported in FAO area 61 (Pacific Northwest)"}
MegaData<-readRDS(file = here("data","MegaData.rds")) 

overfished_bau <- MegaData %>% 
  filter((1 - Efin_BAU1) > (r / 2))

io <- fao_capture %>% 
  filter(scientific_name %in% unique(overfished_bau$SciName)) %>% 
  group_by(scientific_name, fao_area_code) %>% 
  summarise(tc = sum(capture, na.rm = TRUE)) %>% 
  group_by(scientific_name) %>% 
  mutate(pio = tc / sum(tc)) %>% 
  filter(fao_area_code %in% c(61)) %>% 
  filter(pio > 0.9) %>% 
  arrange(desc(pio, tc)) %>% 
  ungroup() %>% 
  mutate(size = tc / max(tc)) %>% 
  arrange(desc(size))

china_pio_plot <- io %>% 
  ggplot(aes(pio)) + 
  geom_histogram()

# china_pio_plot

cs <- unique(io$scientific_name)

snap <- which((MegaData$SciName %in% cs) & MegaData$Manage == 0)

ShortCoord<-CleanCoordmegacell

check <- mean(KprotectedPerCell_Library[snap,] > 0)

tmp <- ShortCoord %>% 
  mutate(k_per_cell = as.numeric(colSums(KprotectedPerCell_Library[snap,]))) %>% 
  mutate(k_per_cell = ifelse(k_per_cell == 0, NA, k_per_cell))

tmp %>% 
  ggplot(aes(lon, lat, fill = k_per_cell)) + 
  geom_raster() +
  geom_sf(data = land_shp_moll, fill="black", lwd = 0, inherit.aes = F)+ theme(panel.grid.major = element_line(colour = 'transparent')) + 
  scale_fill_viridis_c()


```

This in and of itself is not necessarily concerning: it seems entirely plausible that there are species distributed around the world but only fished in some locations. However, this does pose some challenges to the assumptions made in Cabral et al. 2020. First, from the perspective of benefits, according to the pooled model used in Cabral et al. 2020 conditional on K a large MPA in the Caribbean may be just as beneficial to this subset of fisheries as closing portions of the coral triangle. Second, the pooled biomass model assumes that, conditional on K, all areas have equal fishing mortality rates, and therefore no area is worth more or less than another in terms of its contribution to reducing fishing pressure. For this case study though, based on the same data used to produce the estimates of stock status in Costello et al. 2016, almost none of the fishing mortality for these species comes from areas outside the Pacific Northwest. But, under the assumptions of this model, closing off a K equivalent amount of area in say the Caribbean or off Baja, where relatively little fishing pressure occurs, is identical to closing off a K equivalent amount of area off of the Chinese coast. 

To quantify the potential impact of these choices, we re-ran the BAU scenario from Cabral et al. 2020, but only for this subset of overfished-under BAU stocks caught almost entirely within the Pacific Northeast. Following the Aquamaps distribution, the areas around China produce on a per-cell basis the most increase in harvest according to the model. However, MPAs as far away as the Caribbean produce increases in total catch for this subset of species (Fig.\@ref(fig:cs-mpa-plot)). In total, while for the species in question nearly all report 100% of their catches from within FAO area 61, roughly 30% of the total increase in harvest that the model estimates for this MPA network comes from areas outside of FAO area 61. This result means that these benefits both come from areas that are quite far away from China, for the life history of most species, and from areas where the same data used to produce the estimates used in Cabral et al. 2020 tells us there is little to no fishing pressure for these species (Fig.\@ref(fig:cs-plot)).


```{r}



a = fao_capture %>% 
  filter(scientific_name %in% cs, 
         year > 2010)

catch_breakdown_plot <- a %>% 
  group_by(country, fao_area) %>% 
  summarise(tc = sum(capture)) %>% 
  arrange(desc(tc)) %>%  
ungroup() %>% 
  mutate(pc = tc / sum(tc)) %>% 
  filter(tc > .1) %>% 
  ggplot(aes(country, pc, fill = fao_area)) + 
  geom_col() + 
  coord_flip()  + 
  theme(legend.position = "top")
```

```{r, echo = FALSE, include=FALSE}

MegaData<-readRDS(file = here("data","MegaData.rds"))
Cleanmegacell<-readRDS(file = here("data","Cleanmegacell_mollweide.rds"))
CleanCoordmegacell<-readRDS(file = here("data","CleanCoordmegacell_mollweide.rds"))
KprotectedPerCell_Library<-readRDS(file = here("data","KprotectedPerCell_Library_mollweide.rds"))
MPA_coord<-readRDS(file= here("data","MPA_coord_mollweide.rds")) #this is my code
land_shp_moll<-readRDS(file = here("data","land_shp_moll.rds"))
head(MPA_coord)
dim(MPA_coord)
head(MPA_coord)
dim(MPA_coord)

loc <-
  which((MegaData$SciName %in% cs) &
          MegaData$Manage == 0)

# loc <-
#   which((1 - MegaData$Efin_BAU1) > .3 &
#           MegaData$Manage == 0)[1]

MegaData <- MegaData[loc, ]

KprotectedPerCell_Library <- KprotectedPerCell_Library[loc, ]

#get MPA positions
CleanCoordmegacell_MPA <-
  left_join(CleanCoordmegacell, MPA_coord, by = c("lon", "lat"))
head(CleanCoordmegacell_MPA)
dim(CleanCoordmegacell_MPA)
sum(CleanCoordmegacell_MPA$MPA, na.rm = T)

#positions of 1s (MPAs)
MPAposition <- which(CleanCoordmegacell_MPA$MPA == 1)
head(MPAposition)
length(MPAposition)#2931 --- 2.44% are MPAs
length(MPAposition) * 100 / dim(Cleanmegacell)[1]

##TRY new approach
numcell <- dim(Cleanmegacell)[1]
celltoiterateFULL <- 1:numcell
MPAselect0 <- matrix(0, nrow = numcell, ncol = 1)
PriorityAreas <- c()
NetworkResult <- vector()

#Make MPAselect0==1 for MPAs
MPAselect0[MPAposition] <- 1
# head(MPAselect0)
# sum(MPAselect0)

#remove MPAs from celltoiterateFULL
celltoiterateFULL <- celltoiterateFULL[-MPAposition]
celltoiterate <- celltoiterateFULL
ncell <- length(celltoiterate)


###Compute spillover---PIXEL-LEVEL spillover
K <- MegaData$Kfin # K per species
m <- MegaData$m # mobility per species
r <- MegaData$r

if (scenario == "all managed") {
  E <- MegaData$Emsy
} else if (scenario == "OAconstant") {
  E <- MegaData$Efin
} else if (scenario == "BAU1") {
  E <- MegaData$Efin_BAU1
} else if (scenario == "Efin_msy") {
  E <- MegaData$Efin_msy
} else if (scenario == "EBvK01fin") {
  E <- MegaData$EBvK01fin
}

ER <- 1 - E
ER <- 1 * (ER > 1) + ER * (ER <= 1)
# max(ER)
# min(ER)

MPAselect <- MPAselect0
R <-
  rowSums(KprotectedPerCell_Library[, which(MPAselect == 1), drop = FALSE])
ER_redistribute <- 1 - (1 - ER) ^ (1 / (1 - R))

hbau <-
  na.omit(ER_redistribute * ((m * K * (1 - R)) / ((ER_redistribute * R) +
                                                    m)) * (1 - ((
                                                      ER_redistribute * (1 - R) * m
                                                    ) / (((ER_redistribute * R) + m
                                                    ) * r))))
hbau <- hbau * (hbau > 0)
HBAU <- sum(hbau)
# HBAU

PICKSIZE <- 100 #number of MPA sites selected

nmax <- floor(length(celltoiterate) / PICKSIZE)
# nmax #this is the number of iterations needed for PICKSIZE at a time!

Eevolve <- matrix(nrow = nmax, ncol = dim(MegaData)[1])


if (run_case_study){
cl <- parallel::makeCluster(parallel::detectCores() - 4)

doParallel::registerDoParallel(cl)
for (i in 1:nmax) {
  MPAselectPrev <-
    rowSums(KprotectedPerCell_Library[, which(MPAselect0 == 1), drop = FALSE])
  result <-
    foreach(iter = 1:length(celltoiterate),
            .combine = rbind) %dopar% {
              # print(iter)
              # MPAselect <- MPAselect0
              # MPAselect[celltoiterate[iter]] <- 1
              R <- MPAselectPrev + KprotectedPerCell_Library[, celltoiterate[iter]]
              ER_redistribute <- 1 - (1 - ER) ^ (1 / (1 - R))
              
              b_out <-
                ((m * K * (1 - R)) / (ER_redistribute * R + m)) * (1 - (ER_redistribute * (1 - R) * m) /
                                                                     ((ER_redistribute + m) * r)) 
              
              hmpa <-
                (ER_redistribute * ((m * K * (1 - R)) / ((
                  ER_redistribute * R
                ) + m)) * (1 - ((
                  ER_redistribute * (1 - R) * m
                ) / (((ER_redistribute * R) + m
                ) * r))))
              
              
              # out <- tibble(b_out = b_out, hmpa = hmpa, ER_redistribute = ER_redistribute, K = K)
              # write_rds(out, file = here("storage",paste0("i",i,"_", "iter",iter,".rds")))
              hmpa <- hmpa * (hmpa > 0)
              HMPA <- sum(hmpa)
              HMPA - HBAU
            }
  
  #1. find the location of the top 1000 highest pixel-level
  myorderHightoLow <- order(-result)#positions
  cellselected <-
    myorderHightoLow[1:PICKSIZE] #but these are the position of the temporary pixels, not our reference pixels
  #convert coord to scale comparable to priority areas
  Prioritycellselected <- celltoiterate[cellselected]
  
  #3. block those additional 100 in MPAselect
  MPAselect0[Prioritycellselected] <- 1
  
  #4. save them for our priority areas
  PriorityAreas <- append(PriorityAreas, Prioritycellselected)
  
  #5. Calculate food prov of the additional 100 cells
  MPAselect <- MPAselect0
  R <-
    rowSums(KprotectedPerCell_Library[, which(MPAselect == 1), drop = FALSE])
  ER_redistribute <- 1 - (1 - ER) ^ (1 / (1 - R))
  
  hmpa <-
    na.omit(ER_redistribute * ((m * K * (1 - R)) / ((
      ER_redistribute * R
    ) + m)) * (1 - ((
      ER_redistribute * (1 - R) * m
    ) / (((ER_redistribute * R) + m
    ) * r))))
  hmpa <- hmpa * (hmpa > 0)
  HMPA <- sum(hmpa)
  
  #save result. Comment other parts not needed now.
  NetworkResult[i] <- HMPA - HBAU
  Eevolve[i, ] <- ER_redistribute
  
  #pass this to the top
  celltoiterate <-
    celltoiterateFULL[!celltoiterateFULL %in% PriorityAreas]#celltoiterateFULL[-PriorityAreas]#bacause Prioritycellselected are real numbers, not rank
  
  print(c(i, NetworkResult[i]))
  rm(
    result,
    myorderHightoLow,
    cellselected,
    Prioritycellselected,
    MPAselect,
    R,
    hmpa,
    HMPA
  )
}


  saveRDS(NetworkResult,file = file.path(results_path,"cs_NetworkResult100_BAU1_mollweide.rds"))
  saveRDS(PriorityAreas,file = file.path(results_path, "cs_PriorityAreas100_BAU1_mollweide.rds"))  

} else {
  
    NetworkResult <- readRDS(file = file.path(results_path,"cs_NetworkResult100_BAU1_mollweide.rds"))
    PriorityAreas <- readRDS(file =  file.path(results_path,"cs_PriorityAreas100_BAU1_mollweide.rds") )

  
}
# plot(NetworkResult)

PICKSIZE<-100
BenefitCurve<-as.data.frame(NetworkResult)/1000000
MPAsize<-(length(MPAposition)+1)*100/dim(Cleanmegacell)[1]
#(MPAinEEZ+1)*100/length(EEZposition)#there is +1 because the next pixel starts with +1
BenefitCurve$MPA <- scales::rescale(seq.int(nmax), to = c(MPAsize, 100))
zerozero<-data.frame(0,0)
names(zerozero)<-c("NetworkResult","MPA")
zerozero[1,]<-c(-HBAU/(1000000),100)
BenefitCurve<-rbind(BenefitCurve,zerozero)
theme_set(theme_cowplot())
benefitplot<-ggplot(BenefitCurve, aes(MPA, NetworkResult)) +geom_line(col="blue")+# theme_classic()+
  labs(x="% EEZ protected",y="Change in catch (MMT)",title=paste("Global (max =", round(max(BenefitCurve$NetworkResult),2),"MMT)"))#+geom_hline(yintercept = 0)
# benefitplot

Priority<-as.data.frame(PriorityAreas)
Priority$rank <- ((seq.int(nrow(Priority))/ncell))*100

#add dh
NetworkResult_prime<-as.data.frame(NetworkResult)
dH_prime<-NetworkResult_prime %>% mutate(dH = NetworkResult - lag(NetworkResult, default = 0))
# plot(dH_prime$dH)
Priority$NetworkResult<-rep(NetworkResult, each=PICKSIZE) ## this is adding delta H
Priority$dH<-rep(dH_prime$dH/PICKSIZE, each=PICKSIZE) ## this is adding delta H
# head(Priority)
# dim(Priority)

PriorityFrame <- as.data.frame(seq.int(nrow(CleanCoordmegacell)))
names(PriorityFrame) <- "PriorityAreas"
#add the priority
PriorityFrame2<-left_join(PriorityFrame,Priority, by="PriorityAreas")
PriorityFrame2[is.na(PriorityFrame2)] <- 0
# head(PriorityFrame2)
# dim(PriorityFrame2)

ShortCoord<-CleanCoordmegacell
ShortCoord$rank<-PriorityFrame2$rank
ShortCoord$NetworkResult<- PriorityFrame2$NetworkResult#this is for deriving dh
ShortCoord$dH<- PriorityFrame2$dH#this is for deriving dh
ShortCoord$ID<-row.names(ShortCoord)

# dim(ShortCoord)
# head(ShortCoord)

ShortCoord_Sort <- ShortCoord[order(-ShortCoord$rank),] %>% filter(rank!=-1000)

ShortCoord_Sort$sign<-ShortCoord_Sort$dH>0
InflectPoint<-min(which(ShortCoord_Sort$sign == TRUE))
InflectMPA<-ShortCoord_Sort$rank[InflectPoint]

cs_MPAcoverage<-ShortCoord_Sort %>% filter(sign) %>%  ggplot(aes(x=lon,y=lat)) + #scale_fill_gradient2(low="darkred", mid="white",high="#00539CFF",midpoint = 0, space = "Lab",na.value = "grey50", guide = "colourbar", aesthetics = "fill",name=expression(paste(Delta, "H (MT)")))+
  # scale_fill_viridis_c( values = scales::rescale(c(min(ShortCoord_Sort$rank), InflectMPA, max(ShortCoord_Sort$rank)))) +
  # scale_fill_gradientn(colours = c("forestgreen", "white", "orange"), limits=c(0,100), values = scales::rescale(c(min(ShortCoord_Sort$rank), InflectMPA, max(ShortCoord_Sort$rank))),name="Protection sequence")+
  theme(axis.title.x = element_blank(),axis.title.y = element_blank(), panel.background = element_blank(),legend.position=c(0.63, 0.05), legend.direction = "horizontal")+ #"bottom
  geom_raster(aes(fill = dH))+
  # geom_raster(data=MPA_coord, aes(x=lon, y=lat),fill="cyan")+  #"#EEA47FFF"
  geom_sf(data = land_shp_moll, fill="black", lwd = 0, inherit.aes = F)+ theme(panel.grid.major = element_line(colour = 'transparent')) + 
  scale_fill_viridis_c(option = "C")


ggsave(file.path(results_path,"cs_MPAcoverage.pdf"), cs_MPAcoverage, width = 20, height = 10)
```

```{r cs-mpa-plot, fig.cap = "Delta Harvest of all cells with positive delta harvest selected for subset of stocks overfished under BAU but with 90% or more of catches coming from FAO area 61"}
cs_MPAcoverage
```


```{r cs-plot, fig.cap="A) Histogram of percent of species-level catches reported for individual species within FAO area 61 b) Percent of total possible MPA benefits coming from MPAs outside and inside of FAO area 71." }

# check overlap

tmp_fao <- fao_areas %>% 
  sf::st_transform(sf::st_crs(land_shp_moll))

tmp_cabral <- ShortCoord_Sort %>%
  filter(sign) %>%
  sf::st_as_sf(coords = c("lon", "lat"),
               crs = sf::st_crs(land_shp_moll))

test <- sf::st_join(tmp_cabral, tmp_fao)

# test %>% 
#   ggplot(aes(color = factor(fao_area_code))) +
#   geom_sf()


fao_area_contributions <- test %>% 
  group_by(fao_area_code) %>% 
  summarise(delta_h = sum(dH, na.rm = TRUE)) %>% 
  ungroup() %>% 
  mutate(percent_delta_h = delta_h / sum(delta_h))

# fao_area_contributions %>% 
#   filter(!is.na(fao_area_code)) %>% 
#   ggplot(aes(reorder(fao_area_code,percent_delta_h), percent_delta_h)) + 
#   geom_col()

dh_outside_chinaish_plot <- fao_area_contributions %>% 
  filter(!is.na(fao_area_code)) %>% 
  mutate(chinaish = fao_area_code == 61) %>% 
  group_by(chinaish) %>% 
  summarise(percent_delta_h = sum(percent_delta_h)) %>% 
  ggplot(aes(reorder(chinaish,percent_delta_h), percent_delta_h)) + 
  geom_col() + 
  scale_y_continuous(labels = scales::percent, expand = c(0,NA),
                     name = "% of MPA Harvest Benefits") + 
  scale_x_discrete(labels = c("Outside Area 61", "Inside Area 61"), name = '')


china_pio_plot <- io %>% 
  ggplot(aes(pio)) + 
  geom_histogram() + 
  scale_x_continuous(name = "Catch reported in Area 61", 
                     labels = scales::percent) + 
  scale_y_continuous(name = "# of species", expand = c(0, NA))

china_cs_plot <- china_pio_plot + dh_outside_chinaish_plot + plot_annotation(tag_levels = 'A')


china_cs_plot
```

# Case Study - RAM closures

```{r, include=FALSE}
upsides <- read_csv(here("data","upsides","ProjectionData.csv")) %>% 
  janitor::clean_names()

# upsides %>% 
#   filter(dbase == "RAM", year > 2016, 
#          policy == "BAU", 
#          scenario == "Con. Concern") %>% 
#   ggplot(aes(year, pmin(4,fv_fmsy), color = scenario, group = interaction(scenario, id_orig)))+ 
#   geom_line(alpha = 0.5) + 
#   facet_wrap(~policy,scales = "free_y")

upsides_bau <- upsides %>% 
  filter(
    policy == "BAU", 
    scenario == "Con. Concern") %>% 
  filter(year == max(year)) %>%
  dplyr::rename(bvbmsy_upsides = bv_bmsy,
                fvfmsy_upsides = fv_fmsy) %>% 
  mutate(manage = ifelse(dbase == "FAO",0, 1))

# sum(upsides_bau$catch) # costello et al. 2016 58.2

upsides_bau$check <- (upsides_bau$bvbmsy_upsides * upsides_bau$fvfmsy_upsides) * upsides_bau$msy

# plot(upsides_bau$check, upsides_bau$catch)
# abline(a = 0, b = 1)

mega_data <-readRDS(file = here("data","MegaData.rds")) %>% 
  janitor::clean_names()

global_things <- upsides %>% 
  filter(
    policy == "Historic", 
    scenario == "Historic") %>% 
  filter(year == 2012) %>% 
  group_by(sci_name) %>% 
  summarise(msy = sum(msy),
            g = mean(g)) %>% 
  ungroup()


mega_data <- mega_data %>% 
  left_join(global_things, by = "sci_name") %>% 
  dplyr::rename(msy_fin = ms_yfin,
                msy_total = ms_ytotal)


check_n <- mega_data %>% 
  group_by(manage, sci_name) %>% 
  count()

# 
# mega_data %>% 
#   ggplot(aes(msy, msy_fin)) + 
#   geom_point() + 
#   geom_abline(aes(slope = 1, intercept = 0))

# mega_data %>% 
#   group_by(sci_name) %>% 
#   summarise(msy = unique(msy), msy_fin = sum(msy)) %>% 
#   ggplot(aes(msy, msy_fin)) + 
#   geom_point() + 
#   geom_abline(aes(slope = 1, intercept = 0))


# mega_data %>% 
#   ggplot(aes(msy, msy_total)) + 
#   geom_point() + 
#   geom_abline(aes(slope = 1, intercept = 0))

# now let's comapare the R's

# mega_data %>% 
#   ggplot(aes(r, g)) + 
#   geom_point() + 
#   geom_abline(aes(slope = 1, intercept = 0))

ram_upsides_bau <- upsides_bau %>% 
  filter(manage == 1) %>% 
  mutate(f_bau_upsides = fvfmsy_upsides * g)

ram_stockid <- str_split(ram_upsides_bau$id_orig, pattern = '-', simplify = TRUE)

ram_upsides_bau$rough_stockid <- ram_stockid[,2]

check <- mega_data %>% 
  filter(manage == 1) %>% 
  left_join(ram_upsides_bau %>% select(rough_stockid,bvbmsy_upsides,fvfmsy_upsides,f_bau_upsides), by = c("stockid" = "rough_stockid")) %>% 
  mutate(f_bau  = 1 - efin_bau1) 

check$f_bau <-1*(check$f_bau>1) + check$f_bau*(check$f_bau<=1)


# check %>% 
#   ggplot(aes(f_bau, f_bau_upsides)) + 
#   geom_point() + 
#   geom_abline(slope = 1, intercept = 0, color = "red") + 
#   scale_x_continuous(name = "F BAU Cabral (1 - efin_bau1 that check for negative escapement) ") + 
#   scale_y_continuous(name = "F BAU Upsides")

# Aha, I think this might be what is happening

##RAM Legacy database here

if (!dir.exists(ramlegacy::ram_dir())){
  
  download_ramlegacy(version="4.44") #downloading the latest version, 4.44

}

load_ramlegacy()
RAMDATA<-load_ramlegacy(tables = "timeseries_values_views")
head(RAMDATA$timeseries_values_views)
RAMDATA2<-RAMDATA$timeseries_values_views
head(RAMDATA2)
colnames(RAMDATA2)
RAMDATA3<-RAMDATA2 %>% select(stockid,year,ERbest,ER, FdivFmsy, FdivFmgt)
#remove entries with no ER values
terminalER<-RAMDATA3 %>% filter(!is.na(ER) & !is.na(FdivFmsy)) %>%  group_by(stockid) %>% slice(which.max(year))
#terminalERtest<-RAMDATA2 %>% filter(! (ER=='NA')) %>%  group_by(stockid) %>% slice(which.max(year))
#head(terminalERtest)
head(terminalER)
plot(terminalER$ERbest,terminalER$ER)
hist(terminalER$year)
table(terminalER$ER)
terminalER$stockid ##terminalER is the file containing the stock assessments with terminal Exploitation Rate

check <- check %>% 
  left_join(terminalER, by = "stockid")

er_check_plot <- check %>% 
  ggplot(aes(f_bau, pmin(1,ERbest))) + 
  geom_point() + 
  geom_abline(slope = 1, intercept = 0, color = "red") + 
  scale_x_continuous(name = "F BAU Cabral (1 - efin_bau1 that check for negative escapement) ") + 
  scale_y_continuous(name = "F BAU Ram")

#aha! that's what's happening

check <- check %>% 
  mutate(fvfmsy_bau_cabral = f_bau / (r / 2))


check %>% 
  ggplot(aes(fvfmsy_bau_cabral, pmin(1,ERbest))) + 
  geom_point() + 
  geom_abline(slope = 1, intercept = 0, color = "red") + 
  scale_x_continuous(name = "F BAU Cabral (1 - efin_bau1 that check for negative escapement) ") + 
  scale_y_continuous(name = "ER Ram")


fvfmsy_check_plot <- check %>% 
  ggplot(aes(fvfmsy_bau_cabral, FdivFmsy, size = msy_fin)) + 
  geom_point() + 
  geom_hline(aes(yintercept = 1), linetype = 2) +
  geom_abline(slope = 1, intercept = 0, color = "red") + 
  scale_x_continuous(name = "F/Fmsy BAU Cabral") + 
  scale_y_continuous(name = "F/Fmsy BAU RAM") + 
  scale_size(trans = "sqrt")

a = lm(FdivFmsy ~ fvfmsy_bau_cabral - 1, data = check)

  
check <- check %>% 
  mutate(bias = fvfmsy_bau_cabral - pmin(2,FdivFmsy))

bias_plot <- check %>% 
  ggplot(aes(fvfmsy_bau_cabral, bias)) + 
  geom_point(aes(size = msy_fin)) + 
  geom_smooth() + 
  geom_hline(aes(yintercept = 0)) + 
  scale_x_continuous(name = "F/Fmsy BAU Cabral") + 
  scale_y_continuous(name = "Bias (Cabral - RAM)")




```

Another way to examine the predictions made by Cabral et al. 2020 is to examine the food-maximizing MPA network proscribed for only those stocks present in the RAM Legacy Stock Assessment Database. This has two advantages, in that a) the estimates of stock status are much more reliable and b) stock boundaries are now defined by Chris Free's spatial mapping of RAM stocks. As such, the results presented here should be less affected by errors and biases in both the unassessed estimates of stock status and the translation of Aquamaps SDMS into spatial maps of K. 

We do have some technical questions about the BAU policy for RAM stocks. The BAU exploitation rate for the unassessed stocks appears to be set such that B/B~MSY~ BAU equals the MSY weighted mean B/B~MSY~ BAU from Costello et al. 2016. For the RAM stocks though those values do not match up, and digging closer it seems as though the values have been updated with the BAU values based on the latest RAM database. However, we think there are some issues there. It appears as though Cabral et al. 2020 pulls the most recent exploitation rate from RAM, not F/F~MSY~. BAU Conservation concern from Costello et al. 2016 calls for maintaining current F/F~MSY~, not current exploitation rate. 

This wouldn't matter if Cabral et al. 2020 used the same F~MSY~ values as RAM, but it does not. Fmsy = r/2 in this model, and r is pulled from fishlife etc. In addition, most RAM stocks have shape parameters such that Bmsy < 0.5K. The net result of all of this is that while this model uses the same BAU exploitation rate as RAM, that same exploitation rate can produce a very different F/Fmsy BAU between RAM and Cabral, which is the thing that matters from the perspective of potential yield gains from MPAs. 

To illustrate, we followed the steps in FoodProvisionEfficient.R to pull out the RAM values, but along with the exploitation rates, pulled the F/Fmsy values (keeping only the most recent year of each stock that has both). We then plotted the exploitation rates from RAM against the exploitation rates calculated from Efin_BAU1, and they more or less match up except for a few outliers (not sure what's happening there), so this seems to tell us that this was in fact how the values in Efin_BAU1 were created (Fig.\@ref(fig:er-check-plot)). 

We then converted the exploitation rates to F/Fmsy values using the r values reported in MegaData (f / (r/2)), and plotted those against the BAU F/Fmsy values from RAM. While there is a positive relationship between the two, it is noisy (R^2^ around  0.57), and critically appears to be positively biased at the upper end, i.e. the higher the the model used here says that F/Fmsy BAU is, the lower it the actual RAM F/Fmsy BAU is, often by enough to switch from overfishing under Cabral to underfishing under RAM (Fig.\@ref(fig:fvfmsy_check_plot), Fig.\@ref(fig:bias_check_plot)). While there is also negative bias at the lower F/Fmsy values, it appears as though most of the MSY is concentrated in the positive bias area. 


```{r er-check-plot, fig.cap = "Exploitation rate from Cabral et al. 2020 plotted against most recent exploitation rate reported in RAM"}

er_check_plot

```


```{r fvfmsy-check-plot, fig.cap="F/Fmsy BAU from Cabral et al. against F/Fmsy BAU from RAM"}

fvfmsy_check_plot

```


```{r bias-check-plot, fig.cap="Bias as a function of F/Fmsy BAU Cabral (RAM values truncated at 2 to remove the influence of the different model assumptions"}

bias_plot
```

The net result of all this is that as we understand it the RAM BAU policy implemented here does not match the BAU policy used in Costello et al. 2016, and since what matters from the perspective of food provision from MPAs is BAU F/Fmsy, this could produce some substantially different results. We suspect that this is why you are reporting much higher gains in catches from MPAs for the RAM stocks than the losses from overfishing of RAM stocks estimated by Hilborn et al. 2020. We go through that below, but these issues may be of secondary concern if we are correct about this issue with the RAM stocks. It seems like around 65% of the MSY in the estimates used here come from unassessed stocks, so changing a subset of the RAM stocks might not change the totals tremendously, but it certainly might change the spatial distribution. IF we are correct, the correct BAU for RAM stocks (not factoring in all the conservation concern caveats) would be to calculate the BAU exploitation rate such that the Cabral et al. model F/Fmsy matches F/Fmsy BAU from RAM. 

Taking the Efin_BAU1 for the managed stock at face value, Looking at the resulting map, the model used in Cabral et al. 2020 suggest that a substantial global network of MPAs, including both open ocean and coastal Seas, would produce up to 4.11 MMT in catch benefits for the fisheries in RAM, out of a total included MSY of  `r  scales::comma(sum(MegaData$MSYfin[MegaData$Manage == 1]))`. This suggests that overfishing is currently reducing global catch of RAM fisheries by `r percent(4.1e6 / (sum(MegaData$MSYfin[MegaData$Manage == 1])))`. In contrast, Hilborn et al. 2020, using a near identical version of RAM, estimated that 3%-5% of the potential catch of RAM stocks is lost due to overfishing.

We can then go through and calculate, for each stock in RAM, the percent of the footprint reported in by Chris Free that would, according to Cabral et al. 2020, produce an increase in total catch of RAM stocks. We can repeat the same analysis but only for the top 5% ranking of protected areas. In both cases, the Cabral et al. 2020 model estimates that most RAM stocks could have over 25% of their footprint placed in MPAs while increasing the total amount of catch produced by RAM stocks (Fig.\@ref(fig:ram-protected-plot), Fig.\@ref(fig:ram-top5-protected-plot)). 


```{r load ram data, echo = FALSE, include=FALSE}


#Load MOLLWEIDE projected data
MegaData<-readRDS(file = here("data","MegaData.rds"))
Cleanmegacell<-readRDS(file = here("data","Cleanmegacell_mollweide.rds"))
CleanCoordmegacell<-readRDS(file = here("data","CleanCoordmegacell_mollweide.rds"))
KprotectedPerCell_Library<-readRDS(file = here("data","KprotectedPerCell_Library_mollweide.rds"))
MPA_coord<-readRDS(file= here("data","MPA_coord_mollweide.rds")) #this is my code
land_shp_moll<-readRDS(file = here("data","land_shp_moll.rds"))
head(MPA_coord)
dim(MPA_coord)

#get MPA positions
CleanCoordmegacell_MPA<-left_join(CleanCoordmegacell,MPA_coord,by=c("lon","lat"))
head(CleanCoordmegacell_MPA)
dim(CleanCoordmegacell_MPA)
sum(CleanCoordmegacell_MPA$MPA,na.rm=T)

#positions of 1s (MPAs)
MPAposition<-which(CleanCoordmegacell_MPA$MPA==1)
head(MPAposition)
length(MPAposition)#2931 --- 2.44% are MPAs
length(MPAposition)*100/dim(Cleanmegacell)[1]

##TRY new approach
numcell<-dim(Cleanmegacell)[1]
celltoiterateFULL<-1:numcell
MPAselect0<-matrix(0, nrow=numcell, ncol=1)
PriorityAreas<-c()
NetworkResult<-vector()

#Make MPAselect0==1 for MPAs
MPAselect0[MPAposition]<-1
head(MPAselect0)
sum(MPAselect0)

#remove MPAs from celltoiterateFULL
celltoiterateFULL<-celltoiterateFULL[-MPAposition]
celltoiterate<-celltoiterateFULL
ncell<-length(celltoiterate)

###Compute spillover---PIXEL-LEVEL spillover 

# trim down to only RAM

managed <- MegaData$Manage == 1

MegaData <- MegaData %>% 
  filter(Manage == 1)

K<-MegaData$Kfin # K per species
m<-MegaData$m # mobility per species
r<-MegaData$r

KprotectedPerCell_Library <- KprotectedPerCell_Library[managed,]


if (scenario=="all managed"){
  E<-MegaData$Emsy
}else if(scenario=="OAconstant"){
  E<-MegaData$Efin
}else if(scenario=="BAU1"){  
  E<-MegaData$Efin_BAU1
}else if(scenario=="Efin_msy"){ 
  E<-MegaData$Efin_msy
}else if(scenario=="EBvK01fin"){ 
  E<-MegaData$EBvK01fin 
}

ER<-1-E
ER<-1*(ER>1) + ER*(ER<=1)
max(ER)
min(ER)

MPAselect<-MPAselect0
R<-rowSums(KprotectedPerCell_Library[,which(MPAselect==1),drop=FALSE])
ER_redistribute<-1-(1-ER)^(1/(1-R))


b_outside_bau <-
  ((m * K * (1 - R)) / (ER_redistribute * R + m)) * (1 - (ER_redistribute * (1 - R) * m) /
                                                       ((ER_redistribute + m) * r)) 

hbau<-na.omit(ER_redistribute*((m*K*(1-R))/((ER_redistribute*R)+m))*(1-((ER_redistribute*(1-R)*m)/(((ER_redistribute*R)+m)*r))))
hbau<-hbau*(hbau>0)
HBAU<-sum(hbau)
HBAU

PICKSIZE<-100 #number of MPA sites selected

nmax<-floor(length(celltoiterate)/PICKSIZE)
nmax #this is the number of iterations needed for PICKSIZE at a time!

Eevolve<-matrix(nrow=nmax,ncol=dim(MegaData)[1])
# k_per_cell <- t(as.datKprotectedPerCell_Library)

if (run_ram_exmaple){
  
  cores<-detectCores() - 2
registerDoParallel(cores)
for (i in 1:nmax){ 
  MPAselectPrev<-rowSums(KprotectedPerCell_Library[,which(MPAselect0==1),drop=FALSE])
  a <- Sys.time()
  result <- foreach(iter = 1:length(celltoiterate), .combine = rbind) %dopar% {
    MPAselect<-MPAselect0
    MPAselect[celltoiterate[iter]]<-1
    R<-MPAselectPrev+KprotectedPerCell_Library[,celltoiterate[iter]]
    ER_redistribute<-1-(1-ER)^(1/(1-R))
    
    
    hmpa<-na.omit(ER_redistribute*((m*K*(1-R))/((ER_redistribute*R)+m))*(1-((ER_redistribute*(1-R)*m)/(((ER_redistribute*R)+m)*r))))
    hmpa<-hmpa*(hmpa>0)
    HMPA<-sum(hmpa)
    HMPA-HBAU
  }
  Sys.time() - a
  
  #1. find the location of the top 1000 highest pixel-level
  myorderHightoLow<-order(-result)#positions
  cellselected<-myorderHightoLow[1:PICKSIZE] #but these are the position of the temporary pixels, not our reference pixels
  #convert coord to scale comparable to priority areas
  Prioritycellselected<-celltoiterate[cellselected]
  
  #3. block those additional 100 in MPAselect
  MPAselect0[Prioritycellselected]<-1
  
  #4. save them for our priority areas
  PriorityAreas<-append(PriorityAreas,Prioritycellselected)
  
  #5. Calculate food prov of the additional 100 cells
  MPAselect<-MPAselect0
  R<-rowSums(KprotectedPerCell_Library[,which(MPAselect==1),drop=FALSE])
  ER_redistribute<-1-(1-ER)^(1/(1-R))

  hmpa<-na.omit(ER_redistribute*((m*K*(1-R))/((ER_redistribute*R)+m))*(1-((ER_redistribute*(1-R)*m)/(((ER_redistribute*R)+m)*r))))
  hmpa<-hmpa*(hmpa>0)
  HMPA<-sum(hmpa)
  
  #save result. Comment other parts not needed now.
  NetworkResult[i]<-HMPA-HBAU
  Eevolve[i,]<-ER_redistribute
  
  #pass this to the top
  celltoiterate<-celltoiterateFULL[!celltoiterateFULL %in% PriorityAreas]#celltoiterateFULL[-PriorityAreas]#bacause Prioritycellselected are real numbers, not rank
  
  print(c(i,NetworkResult[i]))
  rm(result,myorderHightoLow,cellselected,Prioritycellselected, MPAselect,R,hmpa,HMPA)
}
plot(NetworkResult)
stopImplicitCluster()

if(scenario=="BAU1"){
  saveRDS(NetworkResult,file = file.path(results_path,"ram_NetworkResult100_BAU1_mollweide.rds"))
  saveRDS(PriorityAreas,file = file.path(results_path, "ram_PriorityAreas100_BAU1_mollweide.rds"))
}else if(scenario=="all managed"){  
  saveRDS(NetworkResult,file = "~/foodGCEfile/NetworkResult100_allmanaged_redistribute.rds")
  saveRDS(PriorityAreas,file = "~/foodGCEfile/PriorityAreas100_allmanaged_redistribute.rds") 
}else if(scenario=="OAconstant"){
  saveRDS(NetworkResult,file = "~/foodGCEfile/NetworkResult100_OAconstant_mollweide_redistribute.rds")
  saveRDS(PriorityAreas,file = "~/foodGCEfile/PriorityAreas100_OAconstant_mollweide_redistribute.rds")   
}else if(scenario=="EBvK01fin"){
  saveRDS(NetworkResult,file = "~/foodGCEfile/NetworkResult100_EBvK01fin_mollweide_redistribute.rds")
  saveRDS(PriorityAreas,file = "~/foodGCEfile/PriorityAreas100_EBvK01fin_mollweide_redistribute.rds") 
}

  
} else {
  
  NetworkResult <-readRDS(file = file.path(results_path,"ram_NetworkResult100_BAU1_mollweide.rds"))
  
  PriorityAreas <- readRDS(file = file.path(results_path,"ram_PriorityAreas100_BAU1_mollweide.rds") )
  
}

PICKSIZE<-100
BenefitCurve<-as.data.frame(NetworkResult)/1000000
MPAsize<-(length(MPAposition)+1)*100/dim(Cleanmegacell)[1]
#(MPAinEEZ+1)*100/length(EEZposition)#there is +1 because the next pixel starts with +1
BenefitCurve$MPA <- rescale(seq.int(nmax), to = c(MPAsize, 100))
zerozero<-data.frame(0,0)
names(zerozero)<-c("NetworkResult","MPA")
zerozero[1,]<-c(-HBAU/(1000000),100)
BenefitCurve<-rbind(BenefitCurve,zerozero)
theme_set(theme_cowplot())
benefitplot<-ggplot(BenefitCurve, aes(MPA, NetworkResult)) +geom_line(col="blue")+# theme_classic()+
  labs(x="% EEZ protected",y="Change in catch (MMT)",title=paste("Global (max =", round(max(BenefitCurve$NetworkResult),2),"MMT)"))#+geom_hline(yintercept = 0)
benefitplot

Priority<-as.data.frame(PriorityAreas)
Priority$rank <- ((seq.int(nrow(Priority))/ncell))*100

#add dh
NetworkResult_prime<-as.data.frame(NetworkResult)
dH_prime<-NetworkResult_prime %>% mutate(dH = NetworkResult - lag(NetworkResult, default = 0))
plot(dH_prime$dH)
Priority$NetworkResult<-rep(NetworkResult, each=PICKSIZE) ## this is adding delta H
Priority$dH<-rep(dH_prime$dH/PICKSIZE, each=PICKSIZE) ## this is adding delta H
head(Priority)
dim(Priority)

PriorityFrame <- as.data.frame(seq.int(nrow(CleanCoordmegacell)))
names(PriorityFrame) <- "PriorityAreas"
#add the priority
PriorityFrame2<-left_join(PriorityFrame,Priority, by="PriorityAreas")
PriorityFrame2[is.na(PriorityFrame2)] <- 0
head(PriorityFrame2)
dim(PriorityFrame2)

ShortCoord<-CleanCoordmegacell
ShortCoord$rank<-PriorityFrame2$rank
ShortCoord$NetworkResult<- PriorityFrame2$NetworkResult#this is for deriving dh
ShortCoord$dH<- PriorityFrame2$dH#this is for deriving dh
ShortCoord$ID<-row.names(ShortCoord)

dim(ShortCoord)
head(ShortCoord)

ShortCoord_Sort <- ShortCoord[order(-ShortCoord$rank),] %>% filter(rank!=-1000)

ShortCoord_Sort$sign<-ShortCoord_Sort$dH>0
InflectPoint<-min(which(ShortCoord_Sort$sign == TRUE))
InflectMPA<-ShortCoord_Sort$rank[InflectPoint]

# MPAcoverage<-ShortCoord_Sort %>% ggplot(aes(x=lon,y=lat,fill=rank)) + #scale_fill_gradient2(low="darkred", mid="white",high="#00539CFF",midpoint = 0, space = "Lab",na.value = "grey50", guide = "colourbar", aesthetics = "fill",name=expression(paste(Delta, "H (MT)")))+
#   scale_fill_gradientn(colours = c("forestgreen", "white", "orange"), limits=c(0,100), values = scales::rescale(c(min(ShortCoord_Sort$rank), InflectMPA, max(ShortCoord_Sort$rank))),name="Protection sequence")+
#   theme(axis.title.x = element_blank(),axis.title.y = element_blank(), panel.background = element_blank(),legend.position=c(0.63, 0.05), legend.direction = "horizontal")+ #"bottom
#   geom_raster()+
#   geom_raster(data=MPA_coord, aes(x=lon, y=lat),fill="cyan")+  #"#EEA47FFF"
#   geom_sf(data = land_shp_moll, fill="black", lwd = 0, inherit.aes = F)+ theme(panel.grid.major = element_line(colour = 'transparent'))
# MPAcoverage


ram_MPAcoverage<-ShortCoord_Sort %>% filter(sign == TRUE) %>%  ggplot(aes(x=lon,y=lat, fill = dH)) + #scale_fill_gradient2(low="darkred", mid="white",high="#00539CFF",midpoint = 0, space = "Lab",na.value = "grey50", guide = "colourbar", aesthetics = "fill",name=expression(paste(Delta, "H (MT)")))+
  # scale_fill_gradientn(colours = c("forestgreen", "white", "orange"), limits=c(0,100), values = scales::rescale(c(min(ShortCoord_Sort$rank), InflectMPA, max(ShortCoord_Sort$rank))),name="Protection sequence")+
  theme(axis.title.x = element_blank(),axis.title.y = element_blank(), panel.background = element_blank(),legend.position=c(0.63, 0.05), legend.direction = "horizontal")+ #"bottom
  geom_raster()+
  # geom_raster(data=MPA_coord, aes(x=lon, y=lat),fill="cyan")+  #"#EEA47FFF"
  geom_sf(data = land_shp_moll, fill="black", lwd = 0, inherit.aes = F)+ theme(panel.grid.major = element_line(colour = 'transparent')) + 
  scale_fill_viridis_c()


```



```{r ram-mpa-map, fig.cap = "Delta harvest by cell for RAM only MPA network"}
ram_MPAcoverage
```


```{r, echo = FALSE, include=FALSE}

# proportion of RAM stocks closed

i <- 43

MegaData$stockid[i]

ShortCoord_Sort %>%
  sf::st_as_sf(coords = c("lon", "lat"),
               crs = sf::st_crs(land_shp_moll)) %>%
  filter(ID %in% which(KprotectedPerCell_Library[i, ] > 0)) %>%
  ggplot() +
    geom_sf(data = land_shp_moll, fill="black", lwd = 0, inherit.aes = F)+ theme(panel.grid.major = element_line(colour = 'transparent')) +
  geom_sf(color = "red") 


# ok looks like those match up well to the free database so can use those for now
#  let's calculate the percent of non-tuna area inside an MPA and see what that looks like


# plot a point map showing points that are inside a non-tuna ram stock. 

ram_stocks <- MegaData %>% 
  ungroup() %>% 
  mutate(i = 1:nrow(.))

klib <- data.table(KprotectedPerCell_Library)

area_fun <- function(i){

stock_k <- tibble(numid =1:ncol(klib), k = as.numeric(klib[i,])) %>% 
  filter(k > 0)
                    
                    
a = ShortCoord_Sort %>%
  mutate(numid = as.numeric(ID)) %>% 
  filter(numid %in% stock_k$numid) %>% 
  left_join(stock_k, by = "numid")

# a = ShortCoord_Sort %>%
#   sf::st_as_sf(coords = c("lon", "lat"),
#                crs = sf::st_crs(land_shp_moll)) %>%
#     mutate(numid = as.numeric(ID)) %>% 
#   filter(numid %in% stock_k$numid) %>% 
#   ggplot() +
#   geom_sf(
#     data = land_shp_moll,
#     fill = "black",
#     lwd = 0,
#     inherit.aes = F
#   ) + theme(panel.grid.major = element_line(colour = 'transparent')) +
#   geom_sf(aes(color = sign), size = .1)
# 
# 
# a
# 

out <- a %>%
  summarise(p_area_protected = mean(sign),
            p_k_protected = weighted.mean(sign, k))

}



ram_stocks <- ram_stocks %>% 
  mutate(p_protected = map(i, area_fun))

ram_stocks_protected_plot <- ram_stocks %>% 
  unnest(cols = p_protected) %>% 
  ggplot(aes(p_k_protected)) + 
  geom_histogram() + 
  scale_y_continuous(name = "# of RAM Stocks",expand = c(0,NA)) +
  scale_x_continuous(labels = scales::percent,
                     name = "% of RAM  Stock's K inside Food-Increasing MPA")
  

```

```{r ram-protected-plot, fig.cap="Histrogram of percent of Free's estimate of RAM footpring protected inside MPAs inside catch increasing MPAs"}
ram_stocks_protected_plot
```

We can repeat the same analysis, but now only for the first 5% of ranked stocks
```{r, echo = FALSE, include=FALSE}

# proportion of RAM stocks closed

i <- 43

MegaData$stockid[i]

ShortCoord_Sort %>%
  sf::st_as_sf(coords = c("lon", "lat"),
               crs = sf::st_crs(land_shp_moll)) %>%
  filter(ID %in% which(KprotectedPerCell_Library[i, ] > 0)) %>%
  ggplot() +
    geom_sf(data = land_shp_moll, fill="black", lwd = 0, inherit.aes = F)+ theme(panel.grid.major = element_line(colour = 'transparent')) +
  geom_sf(color = "red") 


# ok looks like those match up well to the free database so can use those for now
#  let's calculate the percent of non-tuna area inside an MPA and see what that looks like


# plot a point map showing points that are inside a non-tuna ram stock. 

ram_stocks <- MegaData %>% 
  ungroup() %>% 
  mutate(i = 1:nrow(.))

klib <- data.table(KprotectedPerCell_Library)

area_fun <- function(i){

stock_k <- tibble(numid =1:ncol(klib), k = as.numeric(klib[i,])) %>% 
  filter(k > 0)
                    
                    
a = ShortCoord_Sort %>%
  mutate(numid = as.numeric(ID)) %>% 
  filter(numid %in% stock_k$numid) %>% 
  left_join(stock_k, by = "numid")

# a = ShortCoord_Sort %>%
#   sf::st_as_sf(coords = c("lon", "lat"),
#                crs = sf::st_crs(land_shp_moll)) %>%
#     mutate(numid = as.numeric(ID)) %>% 
#   filter(numid %in% stock_k$numid) %>% 
#   ggplot() +
#   geom_sf(
#     data = land_shp_moll,
#     fill = "black",
#     lwd = 0,
#     inherit.aes = F
#   ) + theme(panel.grid.major = element_line(colour = 'transparent')) +
#   geom_sf(aes(color = sign), size = .1)
# 
# 
# a
# 

out <- a %>%
  summarise(p_area_protected = mean(sign & rank < 5),
            p_k_protected = weighted.mean(sign & rank < 5, k))

}



ram_stocks <- ram_stocks %>% 
  mutate(p_protected = map(i, area_fun))

top_5_ram_stocks_protected_plot <- ram_stocks %>% 
  unnest(cols = p_protected) %>% 
  ggplot(aes(p_k_protected)) + 
  geom_histogram() + 
  scale_y_continuous(name = "# of RAM Stocks",expand = c(0,NA)) +
  scale_x_continuous(labels = scales::percent,
                     name = "% of RAM  Stock's K inside Food-Increasing MPA")
  

```

```{r ram-top5-protected-plot, fig.cap = "Histrogram of percent of Free's estimate of RAM footpring protected inside MPAs inside the top 5% ranking of catch increasing MPAs"}
top_5_ram_stocks_protected_plot
```



# Uncertainty in F

General comment here on the problems with stacking models on models (find that paper on the topic). RAM values are already estimates. Upsides are estiamtes from models trained on models. Highly uncertian, and critically likely to have biases and errors that are correlated in space, time, and species. If each stock is assumed independent, then just taking the mean might produce the same expected value (though maybe not given nonlinear impacts of different levels of error). 

Ths bigger philosphical issues is to convey a sense of uncertainty evaluation (e.g. calling sensitiviti analysis error bars) gives an uninformed reader a sense that that estimate is accountig for the main sources of uncertainty in the model. No model can explore every source of error, but given the massive error in the F/Fmsy estimates from upsides, and the fact that in any projection model that F/Fmsy is what matters, this has to be explicitly addressed, or acknowledge that it is not addresed 


# EEZ Stuff




